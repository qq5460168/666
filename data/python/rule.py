#!/usr/bin/env python3
import os
import re
import requests
import json
import logging
from datetime import datetime
from typing import List, Tuple, Dict

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")

# é…ç½®å‚æ•°
RULE_SOURCES_FILE = 'sources.txt'
OUTPUT_FILE = 'merged-filter.txt'
STATS_FILE = 'rule_stats.json'
USER_AGENT = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'

# æ­£åˆ™è¡¨è¾¾å¼æ¨¡å—åŒ–
REGEX_PATTERNS = {
    "comment": re.compile(r'^[!#]'),
    "blank": re.compile(r'^\s*$'),
    "domain": re.compile(r'^(@@)?(\|\|)?([a-zA-Z0-9-*_.]+)(\^|\$|/)?'),
    "element": re.compile(r'##.+'),
    "regex_rule": re.compile(r'^/.*/$'),
    "modifier": re.compile(r'\$(~?[\w-]+(=[^,\s]+)?(,~?[\w-]+(=[^,\s]+)?)*)$')
}

def is_valid_rule(line: str) -> bool:
    """éªŒè¯è§„åˆ™æœ‰æ•ˆæ€§"""
    if REGEX_PATTERNS["comment"].match(line) or REGEX_PATTERNS["blank"].match(line):
        return False
    return any([
        REGEX_PATTERNS["domain"].match(line),
        REGEX_PATTERNS["element"].search(line),
        REGEX_PATTERNS["regex_rule"].match(line),
        REGEX_PATTERNS["modifier"].search(line)
    ])

def download_rules(url: str) -> Tuple[List[str], List[str]]:
    """ä¸‹è½½è§„åˆ™å¹¶éªŒè¯"""
    invalid_rules = []
    valid_rules = []
    try:
        if url.startswith('file:'):
            file_path = url.split('file:')[1].strip()
            with open(file_path, 'r', encoding='utf-8') as f:
                lines = (line.strip() for line in f)
        else:
            resp = requests.get(url, headers={'User-Agent': USER_AGENT}, timeout=15)
            resp.raise_for_status()
            lines = (line.strip() for line in resp.text.splitlines())

        for line in lines:
            if is_valid_rule(line):
                valid_rules.append(line)
            elif line and not (REGEX_PATTERNS["comment"].match(line) or REGEX_PATTERNS["blank"].match(line)):
                invalid_rules.append(line)
    except Exception as e:
        logging.error(f"âš ï¸ ä¸‹è½½å¤±è´¥: {url} - {str(e)}")
    return valid_rules, invalid_rules

def write_stats(rule_count: int) -> None:
    """å†™å…¥è§„åˆ™ç»Ÿè®¡ä¿¡æ¯åˆ° JSON æ–‡ä»¶"""
    stats = {
        "rule_count": rule_count,
        "last_update": datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S UTC')
    }
    try:
        with open(STATS_FILE, 'w', encoding='utf-8') as f:
            json.dump(stats, f, indent=4)
        logging.info(f"âœ… å·²æ›´æ–°ç»Ÿè®¡ä¿¡æ¯: {STATS_FILE}")
    except Exception as e:
        logging.error(f"å†™å…¥ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")

def process_sources(sources: List[str]) -> Tuple[set, Dict[str, List[str]]]:
    """å¤„ç†è§„åˆ™æ¥æº"""
    merged_rules = set()
    error_reports = {}

    for url in sources:
        logging.info(f"ğŸ“¥ æ­£åœ¨å¤„ç†: {url}")
        valid_rules, invalid_rules = download_rules(url)
        merged_rules.update(valid_rules)

        if invalid_rules:
            error_reports[url] = invalid_rules
            logging.warning(f"âš ï¸ å‘ç° {len(invalid_rules)} æ¡æ— æ•ˆè§„åˆ™")

    return merged_rules, error_reports

def save_merged_rules(rules: set, output_file: str) -> None:
    """ä¿å­˜åˆå¹¶åçš„è§„åˆ™åˆ°æ–‡ä»¶"""
    try:
        sorted_rules = sorted(rules, key=lambda x: (
            not x.startswith('||'),
            not x.startswith('##'),
            x
        ))
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write('\n'.join(sorted_rules))
        logging.info(f"âœ… è§„åˆ™åˆå¹¶å®Œæˆï¼Œè¾“å‡ºåˆ° {output_file}")
    except Exception as e:
        logging.error(f"å†™å…¥åˆå¹¶è§„åˆ™æ–‡ä»¶å¤±è´¥: {e}")

def main() -> None:
    logging.info("ğŸ“‚ å¼€å§‹å¤„ç†è§„åˆ™æ–‡ä»¶")

    try:
        # è¯»å–è§„åˆ™æ¥æº
        with open(RULE_SOURCES_FILE, 'r', encoding='utf-8') as f:
            sources = [line.strip() for line in f if line.strip()]
    except FileNotFoundError:
        logging.error(f"è§„åˆ™æ¥æºæ–‡ä»¶ {RULE_SOURCES_FILE} æœªæ‰¾åˆ°ï¼")
        return
    except Exception as e:
        logging.error(f"è¯»å–è§„åˆ™æ¥æºæ–‡ä»¶å¤±è´¥: {e}")
        return

    merged_rules, error_reports = process_sources(sources)

    # ä¿å­˜åˆå¹¶åçš„è§„åˆ™
    save_merged_rules(merged_rules, OUTPUT_FILE)

    # å†™å…¥ç»Ÿè®¡ä¿¡æ¯
    write_stats(len(merged_rules))

if __name__ == "__main__":
    main()
